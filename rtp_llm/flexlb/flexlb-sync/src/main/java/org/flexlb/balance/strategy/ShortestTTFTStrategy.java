package org.flexlb.balance.strategy;

import org.apache.commons.collections4.CollectionUtils;
import org.apache.commons.collections4.MapUtils;
import org.flexlb.balance.LoadBalanceStrategyFactory;
import org.flexlb.cache.service.CacheAwareService;
import org.flexlb.dao.loadbalance.ServerStatus;
import org.flexlb.dao.loadbalance.StrategyErrorType;
import org.flexlb.dao.master.TaskInfo;
import org.flexlb.dao.master.WorkerStatus;
import org.flexlb.dao.route.RoleType;
import org.flexlb.domain.balance.BalanceContext;
import org.flexlb.domain.monitor.SelectMonitorContext;
import org.flexlb.domain.worker.ScoredWorker;
import org.flexlb.enums.LoadBalanceStrategyEnum;
import org.flexlb.service.monitor.EngineHealthReporter;
import org.flexlb.sync.status.EngineWorkerStatus;
import org.flexlb.util.CommonUtils;
import org.flexlb.utils.LoggingUtils;
import org.springframework.stereotype.Component;

import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.ArrayList;
import java.util.Comparator;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

/**
 * 基于最短首Token时间(TTFT)的负载均衡策略
 *
 * <p>该策略通过综合考虑以下因素选择最优Worker： 1. KV-Cache命中率：优先选择缓存命中率高的Worker 2. 排队时间：考虑Worker当前的任务队列情况 3.
 * 调度公平性：在性能相近的Worker间实现负载均衡
 *
 * @author saichen.sm
 * @since 2025/3/10
 */
@Component("shortestTTFTStrategy")
public class ShortestTTFTStrategy implements LoadBalancer {

  private final EngineWorkerStatus engineWorkerStatus;
  private final EngineHealthReporter engineHealthReporter;
  private final CacheAwareService cacheAwareService;

  private static final int MIN_CANDIDATE_COUNT = 1;
  private static final double CANDIDATE_PERCENTAGE = 0.3;
  private static final double TTFT_THRESHOLD_PERCENTAGE = 0.1;
  private static final double STDDEV_THRESHOLD_FACTOR = 0.5;

  public ShortestTTFTStrategy(
      EngineWorkerStatus engineWorkerStatus,
      EngineHealthReporter engineHealthReporter,
      CacheAwareService cacheAwareService) {
    this.engineWorkerStatus = engineWorkerStatus;
    this.engineHealthReporter = engineHealthReporter;
    this.cacheAwareService = cacheAwareService;
    LoadBalanceStrategyFactory.register(LoadBalanceStrategyEnum.SHORTEST_TTFT, this);
  }

  /**
   * 选择最优Worker执行任务
   *
   * @param balanceContext 负载均衡上下文
   * @param roleType Worker角色类型
   * @param group Worker分组
   * @return 选中的服务器状态
   */
  @Override
  public ServerStatus select(BalanceContext balanceContext, RoleType roleType, String group) {
    SelectMonitorContext monitorContext = new SelectMonitorContext();
    monitorContext.setStartTime(System.currentTimeMillis());

    try {
      ServerStatus result = doSelect(balanceContext, monitorContext, roleType, group);
      if (!result.isSuccess()) {
        monitorContext.markError(result.getMessage());
      }
      return result;
    } catch (Exception e) {
      LoggingUtils.warn("Failed to select worker", e);
      monitorContext.setErrorCode("LB_UNKNOWN_ERROR");
      return ServerStatus.code(StrategyErrorType.NO_AVAILABLE_WORKER);
    } finally {
      reportMetrics(balanceContext, monitorContext);
    }
  }

  /**
   * 释放指定Worker上的本地缓存任务
   *
   * @param modelName 模型名称
   * @param ip Worker IP地址
   * @param interRequestId 内部请求ID
   */
  public void releaseLocalCache(String modelName, String ip, Long interRequestId) {
    Map<String, WorkerStatus> workerStatusMap =
        engineWorkerStatus.selectModelWorkerStatus(modelName, RoleType.PREFILL, null);

    LoggingUtils.debug(
        "releaseLocalCache - modelName: {}, ip: {}, interRequestId: {}",
        modelName,
        ip,
        interRequestId);
    LoggingUtils.debug("Available workers: {}", String.join(",", workerStatusMap.keySet()));

    WorkerStatus workerStatus = workerStatusMap.get(ip);
    if (workerStatus != null) {
      workerStatus.removeLocalTask(interRequestId);
    }
  }

  /** 上报负载均衡选择指标 */
  private void reportMetrics(BalanceContext balanceContext, SelectMonitorContext monitorContext) {
    monitorContext.setTotalCost(System.currentTimeMillis() - monitorContext.getStartTime());
    engineHealthReporter.reportPrefillBalanceSelectMetric(
        balanceContext.getMasterRequest().getModel(),
        monitorContext.getErrorCode() == null,
        monitorContext.getErrorCode(),
        monitorContext.getTotalCost(),
        monitorContext.getTokenizeEndTime() - monitorContext.getTokenizeStartTime(),
        monitorContext.getCalcPrefixEndTime() - monitorContext.getCalcPrefixStartTime(),
        monitorContext.getCalcTTFTEndTime() - monitorContext.getCalcTTFTStartTime());
  }

  /**
   * 执行Worker选择的核心逻辑
   *
   * @param balanceContext 负载均衡上下文
   * @param monitorContext 监控上下文
   * @param roleType Worker角色类型
   * @param group Worker分组
   * @return 选中的服务器状态
   */
  private ServerStatus doSelect(
      BalanceContext balanceContext,
      SelectMonitorContext monitorContext,
      RoleType roleType,
      String group) {
    long interRequestId = balanceContext.getInterRequestId();
    String modelName = balanceContext.getMasterRequest().getModel();
    long seqLen = balanceContext.getMasterRequest().getSeqLen();

    LoggingUtils.debug(
        "Starting shortest TTFT selection for model: {}, role: {}", modelName, roleType);

    // 获取可用的Worker列表
    List<WorkerStatus> availableWorkers = getAvailableWorkers(modelName, roleType, group);
    if (CollectionUtils.isEmpty(availableWorkers)) {
      LoggingUtils.warn("No available workers for role: {}", roleType.getCode());
      return ServerStatus.code(StrategyErrorType.NO_AVAILABLE_WORKER);
    }

    monitorContext.setCalcTTFTStartTime(System.currentTimeMillis());

    // 计算每个引擎的缓存匹配结果
    Map<String, Integer> cacheMatchResults =
        getCacheMatchResults(balanceContext, modelName, roleType, group);

    synchronized (ShortestTTFTStrategy.class) {
      List<ScoredWorker> scoredWorkers = scoreWorkers(availableWorkers, cacheMatchResults, seqLen);

      ScoredWorker bestWorker = selectBestWorker(scoredWorkers);
      if (bestWorker == null) {
        LoggingUtils.warn("Failed to find best worker for role: {}", roleType);
        return ServerStatus.code(StrategyErrorType.NO_AVAILABLE_WORKER);
      }

      return finalizeWorkerSelection(bestWorker, balanceContext, roleType, interRequestId, seqLen);
    }
  }

  /** 获取可用的Worker列表 */
  private List<WorkerStatus> getAvailableWorkers(
      String modelName, RoleType roleType, String group) {

    Map<String, WorkerStatus> workerStatusMap =
        engineWorkerStatus.selectModelWorkerStatus(modelName, roleType, group);
    if (MapUtils.isEmpty(workerStatusMap)) {
      return new ArrayList<>();
    }

    return new ArrayList<>(workerStatusMap.values());
  }

  /**
   * 获取缓存匹配结果
   *
   * @param balanceContext 负载均衡上下文
   * @param modelName 模型名称
   * @param roleType Worker角色类型
   * @param group Worker分组
   * @return 缓存匹配结果: key: engineIpPort，value: prefixMatchLength
   */
  private Map<String /*engineIpPort*/, Integer /*prefixMatchLength*/> getCacheMatchResults(
      BalanceContext balanceContext, String modelName, RoleType roleType, String group) {
    List<Long> blockCacheKeys = balanceContext.getMasterRequest().getBlockCacheKeys();
    return cacheAwareService.findMatchingEngines(blockCacheKeys, modelName, roleType, group);
  }

  /** 为所有存活的Worker计算TTFT评分 */
  private List<ScoredWorker> scoreWorkers(
      List<WorkerStatus> workers, Map<String, Integer> cacheMatchResults, long seqLen) {
    return workers.stream()
        .filter(WorkerStatus::isAlive)
        .map(
            workerStatus -> {
              long hitCacheTokens = calculatePrefixMatchLength(workerStatus, cacheMatchResults);
              long prefillTime = TaskInfo.estimatePrefillTimeMs(seqLen, hitCacheTokens);
              long queueTime = workerStatus.getRunningQueueTime().get();
              return new ScoredWorker(workerStatus, prefillTime + queueTime, hitCacheTokens);
            })
        .collect(Collectors.toList());
  }

  /** 完成Worker选择并更新状态 */
  private ServerStatus finalizeWorkerSelection(
      ScoredWorker selectedWorker,
      BalanceContext balanceContext,
      RoleType roleType,
      long interRequestId,
      long seqLen) {
    WorkerStatus workerStatus = selectedWorker.worker();

    logWorkerSelection(selectedWorker, roleType, interRequestId);

    reportCacheHitMetrics(
        balanceContext.getMasterRequest().getModel(),
        roleType,
        workerStatus.getIp(),
        selectedWorker.hitCacheTokens(),
        seqLen);

    TaskInfo task =
        createTaskInfo(
            interRequestId,
            balanceContext.getMasterRequest().getSeqLen(),
            selectedWorker.hitCacheTokens());
    workerStatus.putLocalTask(interRequestId, task);

    return buildServerStatus(selectedWorker, roleType, interRequestId);
  }

  /** 记录Worker选择日志 */
  private void logWorkerSelection(
      ScoredWorker selectedWorker, RoleType roleType, long interRequestId) {
    LocalDateTime now = LocalDateTime.now();
    String formattedDateTime = now.format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss"));

    WorkerStatus workerStatus = selectedWorker.worker();
    LoggingUtils.debug(
        "Selection completed at: {}, requestId: {}", formattedDateTime, interRequestId);
    LoggingUtils.debug(
        "Selected {} worker - ip: {}, port: {}, hitCacheTokens: {}, ttft: {}",
        roleType,
        workerStatus.getIp(),
        workerStatus.getPort(),
        selectedWorker.hitCacheTokens(),
        selectedWorker.ttft());
  }

  /** 上报缓存命中指标 */
  private void reportCacheHitMetrics(
      String modelName, RoleType roleType, String ip, long hitCacheTokens, long seqLen) {
    double hitRate = seqLen > 0 ? hitCacheTokens / (double) seqLen : 0.0;
    engineHealthReporter.reportCacheHitMetrics(modelName, roleType, ip, hitCacheTokens, hitRate);
  }

  /** 创建任务信息 */
  private TaskInfo createTaskInfo(long interRequestId, long inputLength, long prefixLength) {
    TaskInfo task = new TaskInfo();
    task.setLastActiveTimeMs(System.currentTimeMillis());
    task.setInterRequestId(interRequestId);
    task.setInputLength(inputLength);
    task.setPrefixLength(prefixLength);
    return task;
  }

  /**
   * 选择最佳Worker，综合考虑TTFT和调度公平性
   *
   * <p>算法流程： 1. 按TTFT对所有Worker排序 2. 选择前30%的Worker作为候选者（至少1个） 3. 在TTFT相近的候选者中，优先选择最近未被调度的Worker
   *
   * @param scoredWorkers 已评分的Worker列表
   * @return 最佳Worker
   */
  private ScoredWorker selectBestWorker(List<ScoredWorker> scoredWorkers) {
    if (scoredWorkers.isEmpty()) {
      return null;
    }

    List<ScoredWorker> sortedWorkers = sortByTTFT(scoredWorkers);
    List<ScoredWorker> candidates = selectTopCandidates(sortedWorkers);

    if (candidates.isEmpty()) {
      return null;
    }

    long minTTFT = candidates.getFirst().ttft();
    double threshold = calculateTTFTThreshold(candidates);

    List<ScoredWorker> similarWorkers = filterSimilarWorkers(candidates, minTTFT, threshold);

    return selectWorkerByScheduleFairness(similarWorkers, candidates);
  }

  /** 按TTFT对Worker排序 */
  private List<ScoredWorker> sortByTTFT(List<ScoredWorker> workers) {
    return workers.stream().sorted(Comparator.comparingLong(ScoredWorker::ttft)).toList();
  }

  /** 选择前N个候选Worker */
  private List<ScoredWorker> selectTopCandidates(List<ScoredWorker> sortedWorkers) {
    int candidateCount =
        Math.max(MIN_CANDIDATE_COUNT, (int) (sortedWorkers.size() * CANDIDATE_PERCENTAGE));
    return sortedWorkers.stream().limit(candidateCount).toList();
  }

  /** 计算TTFT相似度阈值 */
  private double calculateTTFTThreshold(List<ScoredWorker> candidates) {
    double avgTTFT = candidates.stream().mapToLong(ScoredWorker::ttft).average().orElse(0.0);

    double stdDev =
        Math.sqrt(
            candidates.stream()
                .mapToLong(ScoredWorker::ttft)
                .mapToDouble(v -> Math.pow(v - avgTTFT, 2))
                .average()
                .orElse(0.0));

    return Math.max(avgTTFT * TTFT_THRESHOLD_PERCENTAGE, stdDev * STDDEV_THRESHOLD_FACTOR);
  }

  /** 筛选TTFT相近的Worker */
  private List<ScoredWorker> filterSimilarWorkers(
      List<ScoredWorker> candidates, long minTTFT, double threshold) {
    return candidates.stream()
        .filter(worker -> Math.abs(worker.ttft() - minTTFT) <= threshold)
        .toList();
  }

  /** 根据调度公平性选择Worker 在TTFT相近的Worker中，优先选择最近未被调度的Worker */
  private ScoredWorker selectWorkerByScheduleFairness(
      List<ScoredWorker> similarWorkers, List<ScoredWorker> fallbackCandidates) {
    if (similarWorkers.isEmpty()) {
      return fallbackCandidates.getFirst();
    }

    return similarWorkers.stream()
        .min(Comparator.comparingLong(worker -> worker.worker().getLastScheduleTime().get()))
        .orElse(fallbackCandidates.getFirst());
  }

  /**
   * 构建服务器状态响应
   *
   * @param selectedWorker 已选Worker
   * @param roleType Worker角色类型
   * @param interRequestId 内部请求ID
   * @return 服务器状态
   */
  private ServerStatus buildServerStatus(
      ScoredWorker selectedWorker, RoleType roleType, long interRequestId) {
    WorkerStatus workerStatus = selectedWorker.worker();
    ServerStatus result = new ServerStatus();
    try {
      result.setSuccess(true);
      result.setRole(roleType);
      result.setInterRequestId(interRequestId);
      result.setPrefillTime(selectedWorker.ttft());
      result.setGroup(workerStatus.getGroup());
      result.setServerIp(workerStatus.getIp());
      result.setHttpPort(workerStatus.getPort());
      result.setGrpcPort(CommonUtils.toGrpcPort(workerStatus.getPort()));
    } catch (Exception e) {
      LoggingUtils.error("Failed to build server status for requestId: {}", interRequestId, e);
      result.setCode(StrategyErrorType.NO_AVAILABLE_WORKER.getErrorCode());
      result.setMessage(StrategyErrorType.NO_AVAILABLE_WORKER.getErrorMsg());
      result.setSuccess(false);
    }
    return result;
  }

  /**
   * 计算前缀匹配长度（缓存命中的Token数量）
   *
   * @param workerStatus Worker状态
   * @param cacheMatchResults 缓存匹配结果
   * @return 命中的Token数量
   */
  private long calculatePrefixMatchLength(
      WorkerStatus workerStatus, Map<String, Integer> cacheMatchResults) {
    if (workerStatus.getCacheStatus() == null || cacheMatchResults == null) {
      return 0L;
    }

    Integer prefixMatchLength = cacheMatchResults.get(workerStatus.getIpPort());
    if (prefixMatchLength == null) {
      return 0L;
    }

    long blockSize = workerStatus.getCacheStatus().getBlockSize();
    return blockSize * prefixMatchLength;
  }
}
